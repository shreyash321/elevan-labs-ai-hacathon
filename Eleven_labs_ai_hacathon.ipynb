{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyash321/elevan-labs-ai-hacathon/blob/main/Eleven_labs_ai_hacathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-tkKfaewInCE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio google-generativeai elevenlabs -U assemblyai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBgJYh4i8Bkr",
        "outputId": "4c77a738-53d3-457b-9350-745f49e33c05"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.2/294.2 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.3/113.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# `pip3 install assemblyai` (macOS)\n",
        "#!pip install assemblyai\n",
        "\n",
        "import assemblyai as aai\n",
        "\n",
        "aai.settings.api_key = \"your-api-key\"\n",
        "transcriber = aai.Transcriber()\n",
        "\n",
        "transcript = transcriber.transcribe(\"https://storage.googleapis.com/aai-web-samples/news.mp4\")\n",
        "# transcript = transcriber.transcribe(\"./my-local-audio-file.wav\")\n",
        "print(transcript.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAlfCx1EN434",
        "outputId": "38a9dd68-0b3e-444f-978f-27f46fe514da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm David Curley at the Smithsonian Aaron Space Museum, where we are marking 50 years since man landed and walked on the moon in a lander just like this one. We are going to show you some of the actual ABC News coverage from 50 years ago during that eight day mission of this remarkable achievement. Apollo Eleven's lander, the Eagle, would be the first manned craft to land on the moon. For training, NASA came with an unusual contraption. Neil Armstrong actually had to eject from it once, and then he had a couple of successful flights. ABC News Anchor at the time, 50 years ago, frank Reynolds with a look at that unusual trainer. Apollo Eleven commander Neil Armstrong is at the controls of a lunar landing training vehicle. Testing the reaction control jets, these thrusters stabilize the Lem during landing and takeoff. The LLTV is designed to simulate the behavior of the Lem as it lands in the moon's gravity. Lunar gravity is one 6th that of the Earth's. Neil Armstrong flew one of these vehicles on May 6, 1968, and that flight was nearly his last. Later reports by a NASA investigating team said the crash, which we'll see soon, was caused by a loss of fuel pressure, compounded by a warning light that failed to work. Armstrong's coolness under pressure saved himself and possibly months of delay for the Apollo program. Later that same year, 1968, another test pilot, Joseph Allegrandi, also escaped from an LLTV just before it crashed. The training vehicle then underwent several design modifications and improvements. Engineers had to increase the vehicle's rocket power to help stabilize the craft. That made the LLTV less of a moon gravity simulator, but it improved pilot safety. On June 16, 1969, neil Armstrong flew the vehicle, sometimes called the Flying Bedstead, to several perfect landings. Question was, how does the machine fly? And the answer is that we're very pleased with the way it flies. It's a significant improvement over the LLRV, which we were flying here a year ago. And I think it does an excellent job of actually capturing the handling characteristics of the lunar module in a landing maneuver. It's really a great deal different than any other kind of aircraft that I've ever flown. The the simulation of lunar gravity has some aspects that make this type of flight sufficiently different from anything else we've ever done to make this vehicle very worthwhile. And I'm very pleased that I had the opportunity to get some flights in it here. Just before the Apollo Eleven flight.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[]\n",
        "messages = [\n",
        "  \"how are you ?\",\n",
        "  \"I am doing well,I am emily and i am here to answer your questions from tesla , how may i help you ?\"\n",
        "]"
      ],
      "metadata": {
        "id": "34OsZzy87G1w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as palm\n",
        "\n",
        "palm.configure(api_key=\"your-api-key\")\n",
        "\n",
        "defaults = {\n",
        "  'model': 'models/chat-bison-001',\n",
        "  'temperature': 0.9,\n",
        "  'candidate_count': 1,\n",
        "  'top_k': 40,\n",
        "  'top_p': 0.95,\n",
        "}\n",
        "context = \"Be an customer support agent named 'emily' at tesla who can interact with customers and give your reponse in 30-50 words only not more than that\"\n",
        "examples = [\n",
        "  [  \"no their's no questions\",\n",
        "      \"thankyou for connecting with tesla support team , have a good day\"\n",
        "  ],\n",
        "  [\n",
        "      'my tesla battery is draining faster',\n",
        "      'sorry to hear about that , i will provide a technichian or you may bring your tesla to nearest service center'\n",
        "  ]\n",
        "]\n",
        "def lang_model(question):\n",
        "  messages.append(question)\n",
        "  response = palm.chat(\n",
        "      **defaults,\n",
        "      context=context,\n",
        "      examples=examples,\n",
        "      messages=messages)\n",
        "  g=response.last # Response of the AI to your most recent request\n",
        "  def replace(string, replacements):\n",
        "    new_string = \"\"\n",
        "    for character in string:\n",
        "      if character in replacements:\n",
        "        new_string += replacements[character]\n",
        "      else:\n",
        "        new_string += character\n",
        "    return new_string\n",
        "  string=g\n",
        "  replacements = {\"\\n\" : \" \", \"\\r\" : \" \", \"\\s\" : \" \",\"\\t\":\" \"}\n",
        "  new_string = replace(string,replacements)\n",
        "  messages.append(new_string)\n",
        "  return new_string\n",
        "lang_model(\"my name is eric walter , i took the tesla model s in 2017\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "ClRVqmZY4lcj",
        "outputId": "5257f9fd-737a-4836-bed7-584c0e82c011"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thank you, Eric. I have scheduled a technician to come to your home on Monday at 10am to take a look at your Tesla S. Please let me know if you have any questions.    I also sent you a confirmation email with the details of your appointment.    Thank you for choosing Tesla!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from elevenlabs import generate, play, set_api_key\n",
        "def tts(text):\n",
        "  set_api_key(\"your-api-key\") # Check the guide on how to get a free API key: https://docs.elevenlabs.io/authentication/01-xi-api-key\n",
        "  audio = generate(\n",
        "      text=text,\n",
        "      voice=\"Bella\")\n",
        "  return audio\n",
        "  #play(audio, notebook=True)\n"
      ],
      "metadata": {
        "id": "PgiZH9pwOcSw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_buffer(audio):\n",
        "    # Pad buffer to multiple of 2 bytes\n",
        "    buffer_size = len(audio)\n",
        "    element_size = np.dtype(np.int16).itemsize\n",
        "    if buffer_size % element_size != 0:\n",
        "        audio = audio + b'\\0' * (element_size - (buffer_size % element_size))\n",
        "    return audio"
      ],
      "metadata": {
        "id": "K6ozgyg22MVe"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "def transcribe(audio, state=\"\"):\n",
        "    transcript = transcriber.transcribe(audio)\n",
        "    text=transcript.text\n",
        "    #text = p(audio)[\"text\"]\n",
        "    state += text + \" \"\n",
        "    states = state+state\n",
        "    answer=lang_model(states)#it takes text as input and text as output\n",
        "    audio=tts(answer)#it takes text as input and audio as output\n",
        "    sr, data = 44100, np.frombuffer(pad_buffer(audio), dtype=np.int16)\n",
        "    return (sr,data)\n",
        "\n",
        "#Set the starting state to an empty string\n",
        "gr.Interface(\n",
        "    fn=transcribe,\n",
        "    inputs=[\n",
        "        gr.Audio(source=\"microphone\", type=\"filepath\", streaming=True)\n",
        "    ],\n",
        "    outputs=[\n",
        "        'audio'\n",
        "    ],\n",
        "    live=True).launch(share=True,debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r0JZpNdw9pj0",
        "outputId": "92e3f1ce-5fdf-4f37-cfa6-47368afcff37"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://dabb38a9d3cc58ee82.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dabb38a9d3cc58ee82.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 442, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1392, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1097, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 703, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-66-bdd458887f27>\", line 9, in transcribe\n",
            "    audio=tts(answer)#it takes text as input and audio as output\n",
            "  File \"<ipython-input-13-5486ef0fc06b>\", line 4, in tts\n",
            "    audio = generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/elevenlabs/simple.py\", line 130, in generate\n",
            "    return TTS.generate(text, voice, model, api_key=api_key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/elevenlabs/api/tts.py\", line 21, in generate\n",
            "    response = API.post(url, json=data, api_key=api_key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/elevenlabs/api/base.py\", line 65, in post\n",
            "    return API.request(url, method=\"post\", *args, **kwargs)  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/elevenlabs/api/base.py\", line 53, in request\n",
            "    raise RateLimitError(error)\n",
            "elevenlabs.api.error.RateLimitError: This request exceeds your quota. You have 25 characters remaining, while 1032 characters are required for this request.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://dabb38a9d3cc58ee82.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oJMS8bUjzHdz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}